{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Take Home Test Playground.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLNMkog3APqE"
      },
      "source": [
        "# Why is this Notebook here? \n",
        "This notebook will be containing cells of all the code and notes of my thought process, this is for pure organization and bug fixing purposes only. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A3S861PJVmB"
      },
      "source": [
        "## Project goal: \n",
        "\n",
        "* To build and deploy an algorithm that will compare two input texts and return 1 if they are similar, 0 if they are not similar. \n",
        "* The comparison will be based on the words inside the sentence itself:\n",
        "  * Based on the two samples 1 and 2 should be much more similar than 1 and 3\n",
        "  * I will be looking counting the amount of similar words\n",
        "  * I should consider common \"stop\" words and have them not be considered (similar to how nlp libaries have them built in)\n",
        "  * I should have words be stemmed down and forced to be all lowercase for easy comparison \n",
        "  * Order of words at the moment will matter. \n",
        "  * Will be using lists to structure the data, compared to dictionaries is easier to group together in a tight timeframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t6TT7uSAGQj"
      },
      "source": [
        "# Starting off with assigning the sample text into variables. \n",
        "\n",
        "sample_1 = \"The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you.\"\n",
        "sample_2 = \"The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you.\"\n",
        "sample_3 = \"We are always looking for opportunities for you to earn more points, which is why we also give you a selection of Special Offers. These Special Offers are opportunities to earn bonus points on top of the regular points you earn every time you purchase a participating brand. No need to pre-select these offers, we'll give you the points whether or not you knew about the offer. We just think it is easier that way.\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pxEzk0KhsSk"
      },
      "source": [
        "## Removing Punctuation \n",
        "\n",
        "The current stop word function is starting to do too much, extra tasks inside that function will be done with other functions to make each individual function easier to follow through in case they need to be updated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh_ux6iEhsY8"
      },
      "source": [
        "def remove_Punctuation(text):\n",
        "  # List of punctuation to be removed. \n",
        "  punctuation = [\".\", \",\", \"!\", \"?\"]\n",
        "  \n",
        "  # List to be returned with the updated words. \n",
        "  updated_List = []\n",
        "\n",
        "  # Loop to check for punctuation\n",
        "  for word in text: \n",
        "    if word[-1] in punctuation: \n",
        "      updated_List.append(word[:-1])\n",
        "    else:\n",
        "      updated_List.append(word)\n",
        "\n",
        "  return updated_List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFJ18vq7jQY9",
        "outputId": "752798bc-43c3-41b2-aa45-b926293c2306"
      },
      "source": [
        "# Testing the function\n",
        "text_List = sample_1.split()\n",
        "text_List = remove_Punctuation(text_List)\n",
        "print(text_List)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'easiest', 'way', 'to', 'earn', 'points', 'with', 'Fetch', 'Rewards', 'is', 'to', 'just', 'shop', 'for', 'the', 'products', 'you', 'already', 'love', 'If', 'you', 'have', 'any', 'participating', 'brands', 'on', 'your', 'receipt', \"you'll\", 'get', 'points', 'based', 'on', 'the', 'cost', 'of', 'the', 'products', 'You', \"don't\", 'need', 'to', 'clip', 'any', 'coupons', 'or', 'scan', 'individual', 'barcodes', 'Just', 'scan', 'each', 'grocery', 'receipt', 'after', 'you', 'shop', 'and', \"we'll\", 'find', 'the', 'savings', 'for', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvG32O4_jkht"
      },
      "source": [
        "## Creating Stem Words\n",
        "\n",
        "This function will provide a check to make sure the word coming in are stemmed down for easy analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqX3DHnjkFY"
      },
      "source": [
        "def create_Stem(text):\n",
        "  # List of ends to stem out\n",
        "  stem = [\"ing\", \"ed\", \"n't\", \"'ll\", \"est\"]\n",
        "\n",
        "  # Updated list to return at the end of the function \n",
        "  update_Text = []\n",
        "\n",
        "  for word in text:\n",
        "    if word[-3:] in stem:\n",
        "      update_Text.append(word[:-3])\n",
        "    else:\n",
        "      update_Text.append(word)\n",
        "  \n",
        "  return update_Text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCuuqeTVk-jJ",
        "outputId": "d7eb97a2-c15e-44c1-ea94-6de1e5888950"
      },
      "source": [
        "# Testing the function \n",
        "text_List = sample_1.split()\n",
        "text_List = create_Stem(text_List)\n",
        "print(text_List)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'easi', 'way', 'to', 'earn', 'points', 'with', 'Fetch', 'Rewards', 'is', 'to', 'just', 'shop', 'for', 'the', 'products', 'you', 'already', 'love.', 'If', 'you', 'have', 'any', 'participat', 'brands', 'on', 'your', 'receipt,', 'you', 'get', 'points', 'based', 'on', 'the', 'cost', 'of', 'the', 'products.', 'You', 'do', 'need', 'to', 'clip', 'any', 'coupons', 'or', 'scan', 'individual', 'barcodes.', 'Just', 'scan', 'each', 'grocery', 'receipt', 'after', 'you', 'shop', 'and', 'we', 'find', 'the', 'savings', 'for', 'you.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddycQlYKnGqd"
      },
      "source": [
        "## The Stop Words: \n",
        "* This will be a list of words commonly found in text. \n",
        "* This will be done without importing libaries, but using the stop words found inside all of the samples (similuating that this is the only data I have) \n",
        "* This list of words will be applied to a function that will strip those words from the text before being compared.  \n",
        "* This function will also case check the words to make sure they are all lowercased and stemmed down \n",
        "* This will also remove puncuation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KEpFPrnGP3"
      },
      "source": [
        "def remove_Stop_Words(text):\n",
        "  # Defining the stop words based on the given samples \n",
        "  stop_Words = [\"the\", \"to\", \"with\", \"is\", \"for\", \"you\", \"if\", \"have\", \"any\", \"on\", 'your', 'of', 'or']\n",
        "\n",
        "  # Both lists that will \n",
        "  new_Text = []\n",
        "\n",
        "  # Splitting the sting into a list so it will not return the individal letters. \n",
        "  text_List = text.split()\n",
        "\n",
        "  # Removing the punctuation\n",
        "  text_List = remove_Punctuation(text_List)\n",
        "\n",
        "  # Stemming down the words\n",
        "  text_List = create_Stem(text_List)\n",
        "\n",
        "  # For loop to take the list of words, compares each string to the strings inside the stop_Words list and ignores \n",
        "  # if string is in the stop_Words list, if not then will be appended to the new list that will be returned. \n",
        "  # The if statement will automatically lowercase each word\n",
        "  for word in text_List:\n",
        "    # checking if the initial word is in the stop check\n",
        "    if word.lower() in stop_Words: \n",
        "      continue\n",
        "    else:\n",
        "      new_Text.append(word.lower())\n",
        "    \n",
        "  return new_Text\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GCvdA5ZtYZe",
        "outputId": "a9c12952-2646-4154-9fcf-04188e0b7b88"
      },
      "source": [
        "# # Testing to see if the function works. \n",
        "print(remove_Stop_Words(sample_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['easi', 'way', 'earn', 'points', 'fetch', 'rewards', 'just', 'shop', 'products', 'already', 'love', 'participat', 'brands', 'receipt', 'get', 'points', 'based', 'cost', 'products', 'do', 'need', 'clip', 'coupons', 'scan', 'individual', 'barcodes', 'just', 'scan', 'each', 'grocery', 'receipt', 'after', 'shop', 'and', 'we', 'find', 'savings']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_o7cWxyj5ic"
      },
      "source": [
        "## The function: \n",
        "* Starting with a **Jaccard Similarity** function that will directly compare which words are the same between each sample text. \n",
        "* This will calculate that based on the size of shared similar words divided by the total number of words in both texts.\n",
        "* This function will also take in the stop words into consideration and remove the stop words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXdGpJgHiR1Q"
      },
      "source": [
        "def jaccard_Similarity(text1, text2):\n",
        "  # Slimming down text from junk\n",
        "  text1, text2 = remove_Stop_Words(text1), remove_Stop_Words(text2)\n",
        "\n",
        "  # Grabbing all of the text shared between the two\n",
        "  shared_text = set(text1).intersection(set(text2))\n",
        "  \n",
        "  # Now grabbing combined count of all of the text in general\n",
        "  all_text = set(text1).union(set(shared_text))\n",
        "\n",
        "  # Getting the result, if it has more than 50% similarty\n",
        "  # Function will return 1, if less than 50% return 0\n",
        "  result = 100*(len(shared_text)/len(all_text))\n",
        "\n",
        "  if result > 50:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8krNBmLjL2k",
        "outputId": "e145416d-d4e0-4979-bb3a-8ef2e78f45c8"
      },
      "source": [
        "# Testing the function \n",
        "\n",
        "# Between sample 1 and sample 2\n",
        "print(jaccard_Similarity(sample_1, sample_2))\n",
        "\n",
        "# Between 1 and 3\n",
        "print(jaccard_Similarity(sample_1, sample_3))\n",
        "\n",
        "# Between 2 and 3\n",
        "print(jaccard_Similarity(sample_2, sample_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Rl8sZcjTgq"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}